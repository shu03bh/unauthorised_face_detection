{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f75465d4-6925-4102-9ece-251398c8584a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyttsx3 in /home/shubh/.local/lib/python3.10/site-packages (2.98)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: yagmail in /home/shubh/.local/lib/python3.10/site-packages (0.15.293)\n",
      "Requirement already satisfied: premailer in /home/shubh/.local/lib/python3.10/site-packages (from yagmail) (3.10.0)\n",
      "Requirement already satisfied: cssutils in /home/shubh/.local/lib/python3.10/site-packages (from premailer->yagmail) (2.11.1)\n",
      "Requirement already satisfied: cssselect in /home/shubh/.local/lib/python3.10/site-packages (from premailer->yagmail) (1.3.0)\n",
      "Requirement already satisfied: cachetools in /home/shubh/.local/lib/python3.10/site-packages (from premailer->yagmail) (5.3.3)\n",
      "Requirement already satisfied: requests in /home/shubh/.local/lib/python3.10/site-packages (from premailer->yagmail) (2.32.3)\n",
      "Requirement already satisfied: lxml in /home/shubh/.local/lib/python3.10/site-packages (from premailer->yagmail) (5.4.0)\n",
      "Requirement already satisfied: more-itertools in /usr/lib/python3/dist-packages (from cssutils->premailer->yagmail) (8.10.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->premailer->yagmail) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->premailer->yagmail) (2020.6.20)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/shubh/.local/lib/python3.10/site-packages (from requests->premailer->yagmail) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->premailer->yagmail) (1.26.5)\n"
     ]
    }
   ],
   "source": [
    "# Step-by-step notebook code for a complete Home Security System using Hybrid AlexNet+ResNet\n",
    "# Project: Facial recognition with alert for unauthorized faces (strangers)\n",
    "\n",
    "# --- CELL 1: Imports and Setup ---\n",
    "!pip install torch torchvision opencv-python numpy matplotlib --quiet\n",
    "!pip install pyttsx3\n",
    "!pip install yagmail\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os, cv2, time\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "from torchvision.models import AlexNet_Weights, ResNet18_Weights\n",
    "import cv2, time, os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import pyttsx3\n",
    "from email.mime.text import MIMEText\n",
    "import smtplib\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import yagmail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b836ebf-2033-4ec8-8a85-0b6caf29092f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELL 2: Define Hybrid Model (Fixed for BCEWithLogitsLoss) ---\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class HybridAlexResNet(nn.Module):\n",
    "    def __init__(self, num_classes=1):\n",
    "        super().__init__()\n",
    "        # Load pretrained feature extractors\n",
    "        self.alex = models.alexnet(weights=models.AlexNet_Weights.DEFAULT).features\n",
    "        self.res = nn.Sequential(\n",
    "            *list(models.resnet18(weights=models.ResNet18_Weights.DEFAULT).children())[:-1]\n",
    "        )\n",
    "\n",
    "        # Combined feature vector size = 256*6*6 (AlexNet) + 512 (ResNet)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256*6*6 + 512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes)\n",
    "            # ❌ Removed Sigmoid\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        a = torch.flatten(self.alex(x), 1)\n",
    "        r = torch.flatten(self.res(x), 1)\n",
    "        x = torch.cat((a, r), dim=1)\n",
    "        return self.classifier(x)  # Raw logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd480a40-a93a-4289-8eea-4584e7e220d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELL 3: Dataset Class ---\n",
    "# --- CELL 3: Dataset Class ---\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "class FaceDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "        image = self.transform(image)\n",
    "        return image, torch.tensor(self.labels[idx], dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72cede9d-50cf-41fb-8ace-0763d17bbef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found images: 21\n",
      "Sample image paths: ['faces/authorized/user2/2025-05-03-141335.jpg', 'faces/authorized/user2/2025-05-03-141328.jpg', 'faces/authorized/user1/2025-05-01-223920.jpg']\n"
     ]
    }
   ],
   "source": [
    "# --- CELL 4: Load Dataset ---\n",
    " # Only authorized faces stored here\n",
    "# --- CELL 4: Load Dataset (Improved for nested folder) ---\n",
    "import os\n",
    "from torchvision import transforms\n",
    "\n",
    "authorized_dir = 'faces/authorized'\n",
    "strangers_dir = 'faces/strangers'\n",
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "# Walk through each subfolder inside 'authorized'\n",
    "for root, dirs, files in os.walk(authorized_dir):\n",
    "    for file in files:\n",
    "        if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_paths.append(os.path.join(root, file))\n",
    "            labels.append(1)  # All are authorized# Load stranger images\n",
    "            \n",
    "for img in os.listdir(strangers_dir):\n",
    "    if img.endswith(('.jpg', '.png')):\n",
    "        image_paths.append(os.path.join(strangers_dir, img))\n",
    "        labels.append(0)  # Stranger\n",
    "            \n",
    "\n",
    "print(\"Found images:\", len(image_paths))\n",
    "print(\"Sample image paths:\", image_paths[:3])\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "dataset = FaceDataset(image_paths, labels, transform)\n",
    "loader = DataLoader(dataset, batch_size=4, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5a90eac-3735-4b9a-bb7b-20a1b7c2d7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Current LR: 0.0001\n",
      "Epoch 1/1 | Train Loss: 0.4689 | Val Loss: 0.2473\n",
      "✅ Training complete. Best validation loss: 0.2472943812608719\n"
     ]
    }
   ],
   "source": [
    "# --- CELL 5: Train the Model (Fixed) ---\n",
    "\n",
    "# Make sure your HybridAlexResNet DOES NOT include Sigmoid in the final layer if you're using BCEWithLogitsLoss\n",
    "\n",
    "model = HybridAlexResNet()  # Your model must return raw logits (no sigmoid)\n",
    "criterion = nn.BCEWithLogitsLoss()  # More numerically stable than BCE + Sigmoid\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=1e-4, weight_decay=1e-4  # L2 regularization\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, factor=0.5, patience=2  # Reduce LR if val_loss plateaus\n",
    ")\n",
    "\n",
    "# Split dataset into 80% train and 20% validation\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_ds, val_ds = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Use num_workers=0 if you're on Windows or face issues; keep pin_memory=False if not using GPU\n",
    "train_loader = DataLoader(train_ds, batch_size=8, shuffle=True, num_workers=0, pin_memory=False)\n",
    "val_loader   = DataLoader(val_ds, batch_size=8, shuffle=False, num_workers=0, pin_memory=False)\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "num_epochs = 1\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    # ---- Training Phase ----\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        outputs = model(images).view(-1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    # Show learning rate\n",
    "    for param_group in optimizer.param_groups:\n",
    "        print(f\"[Epoch {epoch}] Current LR: {param_group['lr']}\")\n",
    "\n",
    "    # ---- Validation Phase ----\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            outputs = model(images).view(-1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "    val_loss /= len(val_loader)\n",
    "\n",
    "    # Step the scheduler\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # Save best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), \"best_hybrid_model.pth\")\n",
    "\n",
    "    print(f\"Epoch {epoch}/{num_epochs} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "print(\"✅ Training complete. Best validation loss:\", best_val_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f02c556d-e9a7-4316-bc33-92e6b780141c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HybridAlexResNet(\n",
       "  (alex): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (res): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=9728, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- CELL 6: Load Model for Inference ---\n",
    "model.load_state_dict(torch.load(\"hybrid_model.pth\" , map_location=torch.device('cpu')))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6190a8-1941-4023-9a31-791605fa1048",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring XDG_SESSION_TYPE=wayland on Gnome. Use QT_QPA_PLATFORM=wayland to run on Wayland anyway.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Score: -4.5904\n",
      "🖼️ Stranger snapshot saved at strangers/stranger_1747198199.jpg\n",
      "Prediction Score: -5.2973\n",
      "🖼️ Stranger snapshot saved at strangers/stranger_1747198206.jpg\n",
      "Prediction Score: -1.0397\n",
      "🖼️ Stranger snapshot saved at strangers/stranger_1747198212.jpg\n",
      "Prediction Score: -5.0423\n",
      "🖼️ Stranger snapshot saved at strangers/stranger_1747198217.jpg\n",
      "Prediction Score: -3.5129\n",
      "🖼️ Stranger snapshot saved at strangers/stranger_1747198219.jpg\n",
      "Failed to send email: HTTP Error 400: Bad Request\n",
      "Cooldown active. Please wait 9 seconds.\n",
      "Cooldown active. Please wait 8 seconds.\n",
      "Cooldown active. Please wait 3 seconds.\n",
      "Cooldown active. Please wait 2 seconds.\n",
      "Prediction Score: 0.9567\n",
      "Prediction Score: 1.8321\n",
      "Prediction Score: 1.0866\n",
      "Prediction Score: 1.6843\n",
      "Prediction Score: 1.6080\n",
      "Prediction Score: 2.0221\n",
      "Prediction Score: 1.7000\n",
      "Prediction Score: 0.9590\n",
      "Prediction Score: 1.3882\n",
      "Prediction Score: 1.5386\n",
      "Prediction Score: 0.0424\n",
      "🖼️ Stranger snapshot saved at strangers/stranger_1747198268.jpg\n",
      "Prediction Score: -0.2105\n",
      "🖼️ Stranger snapshot saved at strangers/stranger_1747198272.jpg\n",
      "Prediction Score: 0.7326\n",
      "Prediction Score: 0.8970\n",
      "Prediction Score: 0.3242\n",
      "🖼️ Stranger snapshot saved at strangers/stranger_1747198286.jpg\n",
      "Prediction Score: 1.4469\n",
      "Prediction Score: 0.9052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "aplay: pcm_write:2127: write error: Interrupted system call\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import torch\n",
    "import pyttsx3\n",
    "import yagmail\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# --- Voice Engine ---\n",
    "engine = pyttsx3.init()\n",
    "engine.setProperty('rate', 150)  # Adjust speech rate\n",
    "engine.setProperty('volume', 1.0)  # Max volume\n",
    "\n",
    "def speak(text):\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "# --- Transformation for Face Image ---\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# --- Load Pre-trained Model ---\n",
    "# Ensure your model is loaded appropriately\n",
    "# Example:\n",
    "# model = torch.load('your_model.pth')\n",
    "# model.eval()\n",
    "\n",
    "# --- Email Alert Function using Yagmail with OAuth2 ---\n",
    "def send_email_alert():\n",
    "    try:\n",
    "        yag = yagmail.SMTP('agrawalshubhangi03@gmail.com', oauth2_file='credentials.json')\n",
    "        yag.send(\n",
    "            to='agrawalshubhangi03@gmail.com',\n",
    "            subject='Home Security Alert',\n",
    "            contents='Stranger detected by your home security system after 5 failed attempts.'\n",
    "        )\n",
    "        print(\"Alert email sent successfully!\")\n",
    "    except Exception as e:\n",
    "        print(\"Failed to send email:\", e)\n",
    "\n",
    "# --- Face Detection & Webcam ---\n",
    "cap = cv2.VideoCapture(0)\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "frame_count = 0\n",
    "stranger_count = 0\n",
    "cooldown = False\n",
    "cooldown_start_time = None\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    frame_count += 1\n",
    "    if not ret or frame_count % 5 != 0:\n",
    "        continue  # Skip frames for better speed\n",
    "\n",
    "    if cooldown:\n",
    "        elapsed_time = time.time() - cooldown_start_time\n",
    "        if elapsed_time < 10:\n",
    "            remaining_time = int(10 - elapsed_time)\n",
    "            print(f\"Cooldown active. Please wait {remaining_time} seconds.\")\n",
    "            speak(f\"Cooldown active. Please wait {remaining_time} seconds.\")\n",
    "            continue\n",
    "        else:\n",
    "            cooldown = False\n",
    "            stranger_count = 0\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        face_img = frame[y:y+h, x:x+w]\n",
    "        face_pil = Image.fromarray(cv2.resize(face_img, (224,224))).convert('RGB')\n",
    "        face_tensor = transform(face_pil).unsqueeze(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred = model(face_tensor).item()\n",
    "\n",
    "        print(f\"Prediction Score: {pred:.4f}\")\n",
    "\n",
    "        if pred >= 0.7:\n",
    "            label = 'Authorized'\n",
    "            color = (0,255,0)\n",
    "            stranger_count = 0  # Reset counter on successful recognition\n",
    "            speak(\"Authentication granted.\")\n",
    "        else:\n",
    "            label = 'Stranger'\n",
    "            color = (0,0,255)\n",
    "            stranger_count += 1\n",
    "            speak(f\"Authentication not granted. Attempt {stranger_count} of 5.\")\n",
    "            ts = int(time.time())\n",
    "            if not os.path.exists(\"strangers\"):\n",
    "                os.makedirs(\"strangers\")\n",
    "            filename = f'strangers/stranger_{ts}.jpg'\n",
    "            cv2.imwrite(filename, face_img)\n",
    "            print(f\"🖼️ Stranger snapshot saved at {filename}\")\n",
    "\n",
    "            if stranger_count >= 5:\n",
    "                send_email_alert()\n",
    "                speak(\"Maximum unauthorized attempts reached. Alert email sent.\")\n",
    "                cooldown = True\n",
    "                cooldown_start_time = time.time()\n",
    "\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "        cv2.putText(frame, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "\n",
    "    cv2.imshow(\"Security Feed\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c692af6-6f75-4b29-b3db-b9a797285151",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
